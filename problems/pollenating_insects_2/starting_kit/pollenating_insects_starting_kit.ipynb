{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><a href=\"http://www.datascience-paris-saclay.fr\">Paris Saclay Center for Data Science</a></h1>\n",
    "<h2>RAMP on Pollinating insect classification</h2>\n",
    "\n",
    "<i> Mehdi Cherti (CNRS), Romain Julliard (MNHN), Gregoire Lois (MNHN), Balázs Kégl (CNRS)</i><br>\n",
    "    \n",
    "<h2>Introduction</h2>\n",
    "\n",
    "Pollinating insects play a fundamental role in the stability of ecosystems. An insect is said to be pollinator when it transports pollen from one flower to another, helping them to accomplish fertilization. The vast majority of plants pollinates using insects, and at the same time, these insects depend on plants for their survival. However, because of human intensified agrigulture, urbanisation and climate change, these species are threatened. 35% of human alimentation is based on plants pollinated by insects. Diversity of these insects is also important, the more diverse they are the best overall assistance is provided by these insects.\n",
    "\n",
    "The <a href=http://www.spipoll.org/>SPIPOLL</a> (Suivi Photographique des Insectes POLLinisateurs) project proposes to quantitatively study pollinating insects in France. For this, they created a crowdsourcing platform where anyone can upload pictures of insects and identify their species through a series of questions. These data are then used by specialists for further analyses.\n",
    "\n",
    "<h2>Data</h2>\n",
    "\n",
    "In this RAMP, we propose a dataset of pictures of insects from different species gathered from the SPIPOLL project and labeled by specialists. The dataset contains a set of 68815 labeled pictures of insects coming from 209 different insect species. Each picture is a color image. The size of the images (number of pixels) vary.\n",
    "\n",
    "<h2>The prediction task</h2>\n",
    "\n",
    "The goal of this RAMP is to classify correctly the species of the insects. For each submission, you will have to provide an image preprocessor (to standardize, resize, crop, augment images) and batch classifier, which will fit a training set and predict the classes (species) on a test set. The images are big so loading them into the memory at once is impossible. The batch classifier therefore will access them through a generator which can be \"asked for\" a certain number of training and validation images at a time. You will typically run one minibatch of stochastique gradient descent on these images to train a deep convolutional neural networks which are the state of the art in image classification.\n",
    "\n",
    "<h2>Hints</h2>\n",
    "\n",
    "First of all, even though 68K images is relatively small compared to industrial level data sets, to achieve state-of-the-art performance, you will need big networks which will take ages (days) to train on a CPU. If you want to have a faster turnaround for tuning your net, you will need a GPU-equipped server of could instance. Setting up an AWS instance is easy, just follow <a href=https://medium.com/@mateuszsieniawski/keras-with-gpu-on-amazon-ec2-a-step-by-step-instruction-4f90364e49ac#.dariq7i2u>this tutorial</a>. \n",
    "\n",
    "Your main bottleneck is memory. E.g., increasing the resolution to 128x128, you will need to decrease batch size. You should always run user_test_submission.py on the AWS node before submitting.\n",
    "\n",
    "For learning the nuts and bolts of convolutional nets, we suggest that you follow <a href=http://cs231n.github.io/>Andrej Karpathy’s excellent course</a>.\n",
    "\n",
    "You have some trivial \"classical\" options to explore. You should set the epoch size to something more than three (in the starting kit). You should check when the validation error curve flattens because you will also be graded on training and test time. You can change the network architecture, apply different regularization techniques to control overfitting, optimization options to control underfitting.\n",
    "\n",
    "You can use pretrained nets from <a href=https://github.com/fchollet/deep-learning-models>here</a>. There are a couple of examples in the starting kit. Your options are the following.\n",
    "<ol>\n",
    "<li> Retrain or not the weights. If you do not, you are using the pretrained net as fixed a feature extractor. You can add some layers on the top of the output of the pretrained net, and only train your layers. If you retrain all the layers, you use the pretrained net as an initialization. Again, your goal is not only to increase accuracy but also to be frugal. Retraining the full net is obviously more expensive.\n",
    "<li> You can \"read out\" the activations from any layer, you do not need to keep the full net, not even the full convolutional stack.\n",
    "<li> The training kit contains examples with the VGG16 net, but feel free to use any of the other popular nets. Just note that there is no way to change the architecture of these nets. In partticular, each net expects images of a given dimension so your image preprocessing needs to resize or crop the images to the right size.\n",
    "</ol>\n",
    "\n",
    "You can also adjust the image preprocessing. Resizing to small (64x64 or even 32x32) will make the training faster so you can explore more hyperparameters, but the details will be lost so your final result will probably be suboptimal. Insects are mostly centered in the images but there are a lot of smaller insects which could be cropped for a better performance. You can also rotate the images or apply other data augmentation tricks (google \"convolutional nets data augmentation\"). You should also look at the actual images to get some inspiration to find meaningful preprocessing ideas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.io import imread\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "from matplotlib import cm\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from batch_classifier_workflow import train_submission\n",
    "from batch_classifier_workflow import test_submission\n",
    "from batch_classifier_workflow import ArrayContainer\n",
    "\n",
    "import keras.backend as K\n",
    "# K.set_image_ordering('tf')\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "# set \"image_dim_ordering\": \"th\" in ~/.keras/keras.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def _get_image_filename(unique_id):\n",
    "    return 'id_{}.jpg'.format(unique_id)\n",
    "\n",
    "def _download():\n",
    "    \"\"\"\n",
    "    donwload all images and put them in the folder img/.\n",
    "    It requires the command 'wget' to exist.\n",
    "    \"\"\"\n",
    "    \n",
    "    img_folder = 'imgs'\n",
    "    if not os.path.exists(img_folder):\n",
    "        os.makedirs(img_folder)\n",
    "    df = pd.read_csv('train.csv')\n",
    "    for _, cols in df.iterrows():\n",
    "        filename = os.path.join(img_folder, _get_image_filename(cols['id']))\n",
    "        if os.path.exists(filename):\n",
    "            continue\n",
    "        url = cols['picture_url']\n",
    "        cmd = 'wget {} --output-document={}'.format(url, filename)\n",
    "        subprocess.call(cmd, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the images are not yet in 'imgs', run this. Will take ~1h, depending on connection speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "_download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs = {\n",
    "    'chunk_size': 1024,\n",
    "    'n_jobs': 8,\n",
    "    'test_batch_size': 16,\n",
    "    'folder': 'imgs',\n",
    "    'n_classes': 209\n",
    "}\n",
    "\n",
    "def read_data(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    X_values = df['id'].values\n",
    "    X = ArrayContainer(X_values, attrs=attrs)\n",
    "    y = df['class'].values\n",
    "    return X, y\n",
    "\n",
    "def get_cv(y_train_array):\n",
    "    return StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=43)\n",
    "\n",
    "score_function = accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = read_data('train.csv')\n",
    "cv = get_cv(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class distribution is quite heavy tail: 30% of the images are ordinary bees, and about half of the images belong to the three most populous classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')[['taxa_name', 'taxa_code', 'class']]\n",
    "labels_df = train_df.groupby('class').max()[['taxa_name']]\n",
    "counts_df = train_df.groupby('class').count()[['taxa_code']].rename(\n",
    "    columns={'taxa_code': 'count'})\n",
    "labels_df = labels_df.join(counts_df).sort_values('count', ascending=False)\n",
    "labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "\n",
    "reload(sys)  \n",
    "sys.setdefaultencoding('utf8')\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "x = np.arange(len(labels_df))\n",
    "plt.bar(x, labels_df['count'])\n",
    "plt.xticks(x + 0.5, labels_df['taxa_name'], rotation=90, fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worthwhile to look at some image panels, grouped by label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_rows = 4\n",
    "nb_cols = 4\n",
    "nb_elements = nb_rows * nb_cols\n",
    "label = 10\n",
    "\n",
    "print(\"{0}\".format(labels_df.loc[label]))\n",
    "\n",
    "X_given_label = X[y==label]\n",
    "\n",
    "subsample = np.random.choice(X_given_label, replace=False, size=nb_elements)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "grid = AxesGrid(fig, 111, # similar to subplot(141)\n",
    "                nrows_ncols = (nb_rows, nb_cols),\n",
    "                axes_pad = 0.05,\n",
    "                label_mode = \"1\",\n",
    ")\n",
    "for i, image_id in enumerate(subsample):\n",
    "    filename = 'imgs/id_{}.jpg'.format(image_id)\n",
    "    image = imread(filename)\n",
    "    im = grid[i].imshow(image/255.)\n",
    "    grid[i].axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All images have width 1024, with varying height (40% has 768)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_subsample = 1000\n",
    "shapes = np.empty((n_subsample, 3))\n",
    "for i, image_id in enumerate(X[:n_subsample]):\n",
    "    filename = 'imgs/id_{}.jpg'.format(image_id)\n",
    "    image = imread(filename)\n",
    "    shapes[i] = image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes_df = pd.DataFrame(shapes,columns=['height', 'width', 'count'])\n",
    "shapes_df.groupby(['height', 'width']).count().sort_values('count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes_df['height'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image preprocessing\n",
    "\n",
    "In the first workflow element image_preprocessor.py you can resize, crop, or rotate the images. This is an important step. Neural nets need standard-size images defined by the dimension of the input layer. Larger images can contain more detail but they are heavier on memory and training time. Most insects are in the middle of the image, so cropping can be a good strategy (especially non-standard portrait type photos which may be distorted in the \"wrong\" way by simply resizing). Data augmentation by careful random transformations (resize, crop, but also rotate) could be another option to explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'imgs/id_{}.jpg'.format(X[161])\n",
    "image = imread(filename)\n",
    "plt.imshow(image/255.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we resize the images to different resolutions, then blow them up so the difference can be visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "\n",
    "nb_rows = 1\n",
    "nb_cols = 4\n",
    "nb_elements = nb_rows * nb_cols\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "grid = AxesGrid(fig, 111, # similar to subplot(141)\n",
    "                nrows_ncols = (nb_rows, nb_cols),\n",
    "                axes_pad = 0.05,\n",
    "                label_mode = \"1\",\n",
    ")\n",
    "grid[0].imshow(resize(resize(image, (32, 32), preserve_range=True)/255., (224, 224)))\n",
    "grid[0].axis('off')\n",
    "grid[1].imshow(resize(resize(image, (64, 64), preserve_range=True)/255., (224, 224)))\n",
    "grid[1].axis('off')\n",
    "grid[2].imshow(resize(resize(image, (128, 128), preserve_range=True)/255., (224, 224)))\n",
    "grid[2].axis('off')\n",
    "grid[3].imshow(resize(resize(image, (224, 224), preserve_range=True)/255., (224, 224)))\n",
    "grid[3].axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we crop the middle of the image before resizing so there is no distrotion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = image.shape[:2]\n",
    "min_shape = min(h, w)\n",
    "cropped_image = image[h/2 - min_shape / 2:h/2 + min_shape / 2,\n",
    "                      w/2 - min_shape / 2:w/2 + min_shape / 2]\n",
    "plt.imshow(cropped_image/255.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we rotate the image. Explore options in skimage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import rotate\n",
    "\n",
    "nb_rows = 1\n",
    "nb_cols = 4\n",
    "nb_elements = nb_rows * nb_cols\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "grid = AxesGrid(fig, 111, # similar to subplot(141)\n",
    "                nrows_ncols = (nb_rows, nb_cols),\n",
    "                axes_pad = 0.05,\n",
    "                label_mode = \"1\",\n",
    ")\n",
    "grid[0].imshow(rotate(cropped_image, 30, preserve_range=True)/255.)\n",
    "grid[0].axis('off')\n",
    "grid[1].imshow(rotate(cropped_image, 45, preserve_range=True)/255.)\n",
    "grid[1].axis('off')\n",
    "grid[2].imshow(rotate(cropped_image, 60, preserve_range=True)/255.)\n",
    "grid[2].axis('off')\n",
    "grid[3].imshow(rotate(cropped_image, 75, preserve_range=True)/255.)\n",
    "grid[3].axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All these tansformations should be implemented in the transform function found in the image_preprocessor workflow element that you will submit.\n",
    "\n",
    "Note the safeguard that checks if the number of channels (x.shape[2]) is 4. Normally each image has three (RGB) channels, but some of them also contains an opacity channel which we need to ignore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load image_preprocessor.py\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "\n",
    "def transform(x):\n",
    "    if x.shape[2] == 4:\n",
    "        x = x[:, :, 0:3]\n",
    "    x = resize(x, (64, 64), preserve_range=True)\n",
    "    x = x / 255.\n",
    "    x = x.transpose((2, 0, 1))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load pretrained/image_preprocessor.py\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "\n",
    "def transform(x):\n",
    "    if x.shape[2] == 4:\n",
    "        x = x[:, :, 0:3]\n",
    "    x = resize(x, (224, 224), preserve_range=True)\n",
    "    x = x.transpose((2, 0, 1))\n",
    "    # 'RGB'->'BGR'\n",
    "    x = x[::-1, :, :]\n",
    "    # Zero-center by mean pixel\n",
    "    x[0, :, :] -= 103.939\n",
    "    x[1, :, :] -= 116.779\n",
    "    x[2, :, :] -= 123.68\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The batch classifier workflow\n",
    "\n",
    "The data set is too big to be loaded in the memory at once, so instead of a set of images, your batch_classifier.fit function will receive a <i>generator</i>. The type of this generator is BatchGeneratorBuilder. You will interact with it by calling its get_train_valid_generators function. This function will still not return data, since typically you would call the fit function of a keras neural net with it, which would again result in filling the memory too fast. Instead, it returns two other generators that you will pass to the fit_generator function of a keras model. Why two? The first generator will generate training images for keras, and the second generator generates validation images, which you can use to monitor the learning curves when developing the model. Normally you will not need validation samples in your submission (only when you develop your models outside of the RAMP server) unless you implement automatic early stopping based on validation accuracy.\n",
    "\n",
    "The BatchGeneratorBuilder.get_train_valid_generators function expects two parameters: valid_ratio (the ratio of the minibatch that should be used for validation, typically 0.1) and batch_size (the number of images keras fit_generator will get for every minibatch). The batch size is an important hyperparameter. Statistically, a larger batch size means more precise gradient estimates but computationally slower steps. But more importantly, you will have to carefully set the batch size for staying within the memory, depending on the input image size and your network architecture. In the examples in the user test, we use 64, 32, or 8 images per minibatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load batch_classifier_workflow\n",
    "import os\n",
    "import time\n",
    "import threading\n",
    "from importlib import import_module\n",
    "\n",
    "from joblib import delayed\n",
    "from joblib import Parallel\n",
    "\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "\n",
    "def train_submission(module_path, X_array, y_array, train_is):\n",
    "    \"\"\"\n",
    "    module_path : str\n",
    "        module where the submission is. the folder of the module\n",
    "        have to contain batch_classifier.py and image_preprocessor.py.\n",
    "    X_array : ArrayContainer vector of int\n",
    "        vector of image IDs to train on\n",
    "        (it is named X_array to be coherent with the current API,\n",
    "         but as said here, it does not represent the data itself,\n",
    "         only image IDs).\n",
    "    y_array : vector of int\n",
    "        vector of image labels corresponding to X_train\n",
    "    train_is : vector of int\n",
    "       indices from X_array to train on \n",
    "    \"\"\"\n",
    "\n",
    "    # If module_path is not empty (not a local module)\n",
    "    # add the \".\" prefix.\n",
    "    # This is to deal with the import of batch_classifier.py and \n",
    "    # image_preprocessor.py in two different contexts : \n",
    "    # in the context of a submission (the folder submissions/)\n",
    "    # and in the context of the starting kit.\n",
    "    # For a submission, module_path refers to 'submissions.submission_name'.\n",
    "    # In that case, add a '.' to have e.g 'submissions.submission_name.batch_classifier'.\n",
    "    # For the starting kit, module_path is '', in that case we just import\n",
    "    # e.g 'batch_classifier'.\n",
    "    if module_path:\n",
    "        module_path += '.'\n",
    "    batch_classifier = import_module(module_path + 'batch_classifier')\n",
    "    image_preprocessor = import_module(module_path + 'image_preprocessor')\n",
    "    transform_img = image_preprocessor.transform\n",
    "    clf = batch_classifier.BatchClassifier()\n",
    "    attrs = X_array.attrs\n",
    "    test_batch_size = attrs['test_batch_size']\n",
    "    chunk_size = attrs['chunk_size']\n",
    "    n_jobs = attrs['n_jobs']\n",
    "    n_classes = attrs['n_classes']\n",
    "    folder = attrs['folder']\n",
    "    gen_builder = BatchGeneratorBuilder(\n",
    "        X_array[train_is], y_array[train_is],\n",
    "        transform_img,\n",
    "        folder=folder,\n",
    "        chunk_size=chunk_size,\n",
    "        n_classes=n_classes,\n",
    "        n_jobs=n_jobs)\n",
    "    clf.fit(gen_builder)\n",
    "    return transform_img, clf\n",
    "\n",
    "\n",
    "def test_submission(trained_model, X_array, test_is):\n",
    "    \"\"\"\n",
    "    trained_model : tuple (function, Classifier)\n",
    "        tuple of a trained model returned by `train_submission`.\n",
    "    X_array : ArrayContainer of int\n",
    "        vector of image IDs to test on.\n",
    "        (it is named X_array to be coherent with the current API,\n",
    "         but as said here, it does not represent the data itself,\n",
    "         only image IDs).\n",
    "    test_is : vector of int\n",
    "       indices from X_array to test on \n",
    "    \"\"\"\n",
    "    transform_img, clf = trained_model\n",
    "    attrs = X_array.attrs\n",
    "    test_batch_size = attrs['test_batch_size']\n",
    "    chunk_size = attrs['chunk_size']\n",
    "    n_jobs = attrs['n_jobs']\n",
    "    folder = attrs['folder']\n",
    "    it = chunk_iterator(\n",
    "        X_array[test_is], \n",
    "        chunk_size=chunk_size, \n",
    "        folder=folder)\n",
    "    y_proba = []\n",
    "    for X in it:\n",
    "        for i in range(0, len(X), test_batch_size):\n",
    "            # 1) Preprocessing\n",
    "            X_batch = X[i:i + test_batch_size]\n",
    "            X_batch = Parallel(n_jobs=n_jobs, backend='threading')(delayed(transform_img)(x) for x in X_batch)\n",
    "            # X_batch is a list of numpy arrrays at this point, convert it to a single numpy \n",
    "            # array of size `test_batch_size` (at most).\n",
    "            X_batch = [x[np.newaxis, :, :, :] for x in X_batch]\n",
    "            X_batch = np.concatenate(X_batch, axis=0)\n",
    "\n",
    "            # 2) Prediction\n",
    "            y_proba_batch = clf.predict_proba(X_batch)\n",
    "            y_proba.append(y_proba_batch)\n",
    "    y_proba = np.concatenate(y_proba, axis=0)\n",
    "    return y_proba\n",
    "\n",
    "\n",
    "class BatchGeneratorBuilder(object):\n",
    "    \"\"\"\n",
    "    This class is a way to build training and \n",
    "    validation generators that yield each time a tuple (X, y) of mini-batches. \n",
    "    The generators are built in a way to fit into keras API of `fit_generator`\n",
    "    (see https://keras.io/models/model/).\n",
    "    An instance of this class is exposed to users `Classifier` through\n",
    "    the `fit` function : model fitting is called by using\n",
    "    \"clf.fit(gen_builder)\" where `gen_builder` is an instance\n",
    "    of this class : `BatchGeneratorBuilder`.\n",
    "    The fit function from `Classifier` should then use the instance\n",
    "    to build train and validation generators, using the method\n",
    "    `get_train_valid_generators`\n",
    "\n",
    "    Parameters\n",
    "    ==========\n",
    "        \n",
    "    X_array : ArrayContainer of int\n",
    "        vector of image IDs to train on\n",
    "         (it is named X_array to be coherent with the current API,\n",
    "         but as said here, it does not represent the data itself,\n",
    "         only image IDs).\n",
    "\n",
    "    y_array : vector of int\n",
    "        vector of image labels corresponding to `X_array`\n",
    "\n",
    "    folder : str\n",
    "        folder where the images are\n",
    "\n",
    "    chunk_size : int\n",
    "        size of the chunk used to load data from disk into memory.\n",
    "        (see at the top of the file what a chunk is and its difference\n",
    "         with the mini-batch size of neural nets).\n",
    "\n",
    "    n_classes : int\n",
    "        Total number of classes. This is needed because the array\n",
    "        of labels, which is a vector of ints, is transformed into\n",
    "        a onehot representation.\n",
    "\n",
    "    n_jobs : int\n",
    "        the number of jobs used to load images from disk to memory as `chunks`.\n",
    "    \"\"\"\n",
    "    def __init__(self, X_array, y_array, \n",
    "                 transform_img,\n",
    "                 folder='imgs', \n",
    "                 chunk_size=1024,\n",
    "                 n_classes=209,\n",
    "                 n_jobs=8):\n",
    "        self.X_array = X_array\n",
    "        self.y_array = y_array\n",
    "        self.transform_img = transform_img\n",
    "        self.folder = folder\n",
    "        self.chunk_size = chunk_size\n",
    "        self.n_classes = n_classes\n",
    "        self.n_jobs = n_jobs\n",
    "        self.nb_examples = len(X_array)\n",
    "    \n",
    "    def get_train_valid_generators(self, batch_size=256, valid_ratio=0.1):\n",
    "        \"\"\"\n",
    "        This method is used by the user defined `Classifier` to o build train and \n",
    "        valid generators that will be used in keras `fit_generator`.\n",
    "\n",
    "        Parameters\n",
    "        ==========\n",
    "\n",
    "        batch_size : int\n",
    "            size of mini-batches\n",
    "        valid_ratio : float between 0 and 1\n",
    "            ratio of validation data\n",
    "\n",
    "        Returns\n",
    "        =======\n",
    "\n",
    "        a 4-tuple (gen_train, gen_valid, nb_train, nb_valid) where:\n",
    "            - gen_train is a generator function for training data\n",
    "            - gen_valid is a generator function for valid data\n",
    "            - nb_train is the number of training examples\n",
    "            - nb_valid is the number of validation examples\n",
    "        The number of training and validation data are necessary\n",
    "        so that we can use the keras method `fit_generator`.\n",
    "        \"\"\"\n",
    "        nb_valid = int(valid_ratio * self.nb_examples)\n",
    "        nb_train = self.nb_examples - nb_valid\n",
    "        indices = np.arange(self.nb_examples)\n",
    "        train_indices = indices[0:nb_train]\n",
    "        valid_indices = indices[nb_train:]\n",
    "        gen_train = self._get_generator(\n",
    "            indices=train_indices, batch_size=batch_size)\n",
    "        gen_valid = self._get_generator(\n",
    "            indices=valid_indices, batch_size=batch_size)\n",
    "        return gen_train, gen_valid, nb_train, nb_valid\n",
    "\n",
    "    def _get_generator(self, indices=None, batch_size=256):\n",
    "        if indices is None:\n",
    "            indices = np.arange(self.nb_examples)\n",
    "        # Infinite loop, as required by keras `fit_generator`.\n",
    "        # However, as we provide the number of examples per epoch\n",
    "        # and the user specifies the total number of epochs, it will\n",
    "        # be able to end.\n",
    "        while True:\n",
    "            it = chunk_iterator(\n",
    "                X_array=self.X_array[indices],\n",
    "                y_array=self.y_array[indices], \n",
    "                chunk_size=self.chunk_size, \n",
    "                folder=self.folder,\n",
    "                n_jobs=self.n_jobs)\n",
    "            for X, y in it:\n",
    "                # 1) Preprocessing of X and y\n",
    "                X = Parallel(n_jobs=self.n_jobs, backend='threading')(delayed(self.transform_img)(x) for x in X)\n",
    "                # X is a list of numpy arrrays at this point, convert it to a single numpy array.\n",
    "                X = [x[np.newaxis, :, :, :] for x in X]\n",
    "                X = np.concatenate(X, axis=0)\n",
    "                X = np.array(X, dtype='float32')\n",
    "                # Convert y to onehot representation\n",
    "                y = to_categorical(y, nb_classes=self.n_classes)\n",
    "\n",
    "                # 2) Yielding mini-batches\n",
    "                for i in range(0, len(X), batch_size):\n",
    "                    yield X[i:i + batch_size], y[i:i + batch_size]\n",
    "\n",
    "def chunk_iterator(X_array, y_array=None, chunk_size=1024, folder='imgs', n_jobs=8):\n",
    "    \"\"\"\n",
    "    Generator function that yields chunks of images, optionally with their labels.\n",
    "\n",
    "    Parameters\n",
    "    ==========\n",
    "    \n",
    "    X_array : ArrayContainer of int\n",
    "        image ids to load\n",
    "        (it is named X_array to be coherent with the current API,\n",
    "         but as said here, it does not represent the data itself,\n",
    "         only image IDs).\n",
    "\n",
    "    y_array : vector of int\n",
    "        labels corresponding to each image from X_array\n",
    "\n",
    "    chunk_size : int\n",
    "        chunk size\n",
    "\n",
    "    folder : str\n",
    "        folder where the images are\n",
    "\n",
    "    n_jobs : int\n",
    "        number of jobs used to load images in parallel\n",
    "\n",
    "    Yields\n",
    "    ======\n",
    "\n",
    "    if y_array is provided (not None):\n",
    "        it yields each time a tuple (X, y) where X is a list\n",
    "        of numpy arrays of images and y is a list of ints (labels).\n",
    "        The length of X and y is `chunk_size` at most (it can be smaller).\n",
    "\n",
    "    if y_array is not provided (it is None) \n",
    "        it yields each time X where X is a list of numpy arrays\n",
    "        of images. The length of X is `chunk_size` at most (it can be smaller).\n",
    "        This is used for testing, where we don't have/need the labels.\n",
    "\n",
    "    The shape of each element of X in both cases\n",
    "    is (height, width, color), where color is 1 or 3 or 4 and height/width\n",
    "    vary according to examples (hence the fact that X is a list instead of numpy array).\n",
    "    \"\"\"\n",
    "    for i in range(0, len(X_array), chunk_size):\n",
    "        X_chunk = X_array[i:i + chunk_size]\n",
    "        filenames = map(_get_image_filename_from_id, X_chunk)\n",
    "        filenames = map(lambda filename:os.path.join(folder, filename), filenames)\n",
    "        X = Parallel(n_jobs=n_jobs, backend='threading')(delayed(imread)(filename) for filename in filenames)\n",
    "        if y_array is not None:\n",
    "            y = y_array[i:i + chunk_size]\n",
    "            yield X, y\n",
    "        else:\n",
    "            yield X\n",
    "\n",
    "def _get_image_filename_from_id(unique_id):\n",
    "    return 'id_{}.jpg'.format(unique_id)\n",
    "\n",
    "class ArrayContainer(np.ndarray):\n",
    "    \"\"\"\n",
    "    This is an extension of numpy arrays with attributes.\n",
    "    It follows the guidelines from numpy documentation to\n",
    "    subclass numpy arrays to have new attributes.\n",
    "    (Check : https://docs.scipy.org/doc/numpy/user/basics.subclassing.html).\n",
    "    It is used to pass a set of global variables from the problem\n",
    "    to the workflow `batch_classifier_workflow`. \n",
    "    The global variables that are passed (and they are obligatory):\n",
    "    - chunk_size,\n",
    "    - n_jobs,\n",
    "    - test_batch_size,\n",
    "    - folder\n",
    "    - n_classes\n",
    "    \"\"\"\n",
    "    \n",
    "    def __new__(cls, input_array, attrs=None):\n",
    "        # Input array is an already formed ndarray instance\n",
    "        # We first cast to be our class type\n",
    "        obj = np.asarray(input_array).view(cls)\n",
    "        # add the new attribute to the created instance\n",
    "        obj.attrs = attrs\n",
    "        # Finally, we must return the newly created object:\n",
    "        return obj\n",
    "\n",
    "    def __array_finalize__(self, obj):\n",
    "        # see InfoArray.__array_finalize__ for comments\n",
    "        if obj is None: return\n",
    "        self.attrs = getattr(obj, 'attrs', None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your convnet models will be implemented in the batch_classifier.py workflow element. The model is usually implemented in a separate build_model function which is called from init. It does not do any computation, just building the network architecture. The architecture in the starting kit is coming from VGG16 that you can access with other state-of-the-art nets <a href=https://github.com/fchollet/deep-learning-models>here</a>. Your main task is to find the right architecture for this data set. Every parameter is \"free\" the size of the input layer (which should match the preprocessing you do in image_preprocessing.trasform), the number and composition of the convolutional blocks, the size and number of filters in each layer, the number and size of the fully connected layers, the regulariztion that you apply (usually only on the fully connected layers), and the optimizer. In addition, in the fit function you shold decide the size of the minibatches and the number of epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load batch_classifier.py\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import ZeroPadding2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "class BatchClassifier(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = build_model()\n",
    "    \n",
    "    def fit(self, gen_builder):\n",
    "        gen_train, gen_valid, nb_train, nb_valid = gen_builder.get_train_valid_generators(batch_size=64, valid_ratio=0.1)\n",
    "        self.model.fit_generator(\n",
    "                gen_train,\n",
    "                samples_per_epoch=nb_train,\n",
    "                nb_epoch=3,\n",
    "                # In parallel to training, a CPU process loads and preprocesses data from disk and put\n",
    "                # it into a queue in the form of mini-batches of size `batch_size`.`max_q_size` controls \n",
    "                # the maximum size of that queue.\n",
    "                # The size of the queue should be big enough so that the training process (GPU) never\n",
    "                # waits for data (the queue should be never be empty). \n",
    "                # The CPU process loads chunks of 1024 images each time, and\n",
    "                # 1024/batch_size mini-batches from that chunk are put into the queue.\n",
    "                # Assuming training the model on those 1024/batch_size mini-batches is slower than \n",
    "                # loading a single chunk of 1024 images, a good lower bound for `max_q_size` would be\n",
    "                # (1024/batch_size). if `batch_size` is 64, you can put `max_q_size` to 16.\n",
    "                max_q_size=16,\n",
    "                # WARNING : It is obligatory to set `nb_worker` to 1.\n",
    "                # This in principle controls the number of workers used\n",
    "                # by keras to load mini-batches from disk to memory in parallel\n",
    "                # to GPU training. But I don't like the way it works and their\n",
    "                # code is not very commented/used, so I dont trust it that much\n",
    "                # (we might have surprises).\n",
    "                # The way it works in keras is by launching in parallel `nb_worker` \n",
    "                # threads or processes which will all use a copy of the generator passed.\n",
    "                # to `fit_generator`. So if nothing is done and `nb_worker` is set to \n",
    "                # some number > 1, the neural net will be trained with repetitions \n",
    "                # of the same data, because the workers are independent and they got \n",
    "                # through the same generator. \n",
    "                # Hence it is necessary to introduce a shared lock between the the \n",
    "                # processes so that they load different data, this can become a bit \n",
    "                # complicated, so I choose to rather load exactly one chunk at a time using \n",
    "                # 1 worker (so `nb_worker` have to be equal to 1), but do this single\n",
    "                # chunk loading in parallel with joblib.\n",
    "                nb_worker=1,\n",
    "                # if pickle_safe is True, processes are used instead of threads.\n",
    "                # here, 1 process is used because `nb_worker` is 1.\n",
    "                pickle_safe=True,\n",
    "                validation_data=gen_valid,\n",
    "                nb_val_samples=nb_valid,\n",
    "                verbose=1)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.model.predict(X)\n",
    "        \n",
    "def build_model():\n",
    "    # This is VGG16\n",
    "    inp = Input((3, 64, 64))\n",
    "    # Block 1\n",
    "    x = Convolution2D(64, 3, 3, activation='relu', border_mode='same', name='block1_conv1')(inp)\n",
    "    x = Convolution2D(64, 3, 3, activation='relu', border_mode='same', name='block1_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "    # Block 2\n",
    "    x = Convolution2D(128, 3, 3, activation='relu', border_mode='same', name='block2_conv1')(x)\n",
    "    x = Convolution2D(128, 3, 3, activation='relu', border_mode='same', name='block2_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "    # Block 3\n",
    "    x = Convolution2D(256, 3, 3, activation='relu', border_mode='same', name='block3_conv1')(x)\n",
    "    x = Convolution2D(256, 3, 3, activation='relu', border_mode='same', name='block3_conv2')(x)\n",
    "    x = Convolution2D(256, 3, 3, activation='relu', border_mode='same', name='block3_conv4')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "    # Block 4\n",
    "    x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block4_conv1')(x)\n",
    "    x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block4_conv3')(x)\n",
    "    x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block4_conv4')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "    # Block 5\n",
    "    x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block5_conv1')(x)\n",
    "    x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block5_conv3')(x)\n",
    "    x = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='block5_conv4')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "    # dense\n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "    x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "    out = Dense(209, activation='softmax', name='predictions')(x)\n",
    "    model = Model(inp, out)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4), metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following will take a long time if you have no GPUs. You can change the example submission from small to pretrained or ptrtrained_inter, but even the small net will take roughly an hour to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_is, test_is in cv.split(X, y):\n",
    "    print(\"Training ...\")\n",
    "    trained_model = train_submission('small', X, y, train_is)\n",
    "    print(\"Testing ...\")\n",
    "    y_pred = test_submission(trained_model, X, test_is)\n",
    "    print(y[test_is].shape, y_pred[test_is].shape)\n",
    "    score = score_function(y[test_is], y_pred[test_is].argmax(axis=1))\n",
    "    print('accuracy = ', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Pretrained nets\n",
    "\n",
    "In our experience, with the moderate data size we have in this challenge, the best performance is achieved with pretrained nets. When you use a pretrained net, you are copying not only the architecture but also the weights that were saved after training the net, usually on ImageNet. You have some options. 1) include_top means that you also copy the fully connected net from the pretrained net. Usually we do not do that, rather design and traing our fully connected layer on top of the last convolutional layer. 2) trainable means that you retrain also the convolutional weights. If True, it means that you use the pretrained net as an initializer, set to False means you use the pretrained net as a fixed feature extractor.\n",
    "\n",
    "Note that when you use a pretrained net, the image size must match the size that was used to train the net. In current ImageNet classifiers this is rather large (e.g., 224 x 224) which means that you need to decrease the batch size not to crash the GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load pretrained/batch_classifier.py\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import ZeroPadding2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "class BatchClassifier(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = build_model()\n",
    "    \n",
    "    def fit(self, gen_builder):\n",
    "        gen_train, gen_valid, nb_train, nb_valid = gen_builder.get_train_valid_generators(batch_size=16, valid_ratio=0.1)\n",
    "        self.model.fit_generator(\n",
    "                gen_train,\n",
    "                samples_per_epoch=nb_train,\n",
    "                nb_epoch=30,\n",
    "                # In parallel to training, a CPU process loads and preprocesses data from disk and put\n",
    "                # it into a queue in the form of mini-batches of size `batch_size`.`max_q_size` controls \n",
    "                # the maximum size of that queue.\n",
    "                # The size of the queue should be big enough so that the training process (GPU) never\n",
    "                # waits for data (the queue should be never be empty). \n",
    "                # The CPU process loads chunks of 1024 images each time, and\n",
    "                # 1024/batch_size mini-batches from that chunk are put into the queue.\n",
    "                # Assuming training the model on those 1024/batch_size mini-batches is slower than \n",
    "                # loading a single chunk of 1024 images, a good lower bound for `max_q_size` would be\n",
    "                # (1024/batch_size). if `batch_size` is 16, you can put `max_q_size` to 64.\n",
    "                max_q_size=64,\n",
    "                # WARNING : It is obligatory to set `nb_worker` to 1.\n",
    "                # This in principle controls the number of workers used\n",
    "                # by keras to load mini-batches from disk to memory in parallel\n",
    "                # to GPU training. But I don't like the way it works and their\n",
    "                # code is not very commented/used, so I dont trust it that much\n",
    "                # (we might have surprises).\n",
    "                # The way it works in keras is by launching in parallel `nb_worker` \n",
    "                # threads or processes which will all use a copy of the generator passed.\n",
    "                # to `fit_generator`. So if nothing is done and `nb_worker` is set to \n",
    "                # some number > 1, the neural net will be trained with repetitions \n",
    "                # of the same data, because the workers are independent and they got \n",
    "                # through the same generator. \n",
    "                # Hence it is necessary to introduce a shared lock between the the \n",
    "                # processes so that they load different data, this can become a bit \n",
    "                # complicated, so I choose to rather load exactly one chunk at a time using \n",
    "                # 1 worker (so `nb_worker` have to be equal to 1), but do this single\n",
    "                # chunk loading in parallel with joblib.\n",
    "                nb_worker=1,\n",
    "                # if pickle_safe is True, processes are used instead of threads.\n",
    "                # here, 1 process is used because `nb_worker` is 1.\n",
    "                pickle_safe=True,\n",
    "                validation_data=gen_valid,\n",
    "                nb_val_samples=nb_valid,\n",
    "                verbose=1)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.model.predict(X)\n",
    "        \n",
    "def build_model():\n",
    "    vgg16 = VGG16(include_top=False, weights='imagenet')\n",
    "    #vgg16.trainable = False\n",
    "    inp = Input((3, 224, 224))\n",
    "    x = vgg16(inp)\n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "    x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "    out = Dense(209, activation='softmax', name='predictions')(x)\n",
    "    model = Model(inp, out)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=1e-4), metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can also decide not to use the full pretrained net, rather \"read out\" the features from any layer in the convolutional block. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load pretrained_interm/batch_classifier.py\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import ZeroPadding2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "class BatchClassifier(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = build_model()\n",
    "    \n",
    "    def fit(self, gen_builder):\n",
    "        gen_train, gen_valid, nb_train, nb_valid = gen_builder.get_train_valid_generators(batch_size=16, valid_ratio=0.1)\n",
    "        self.model.fit_generator(\n",
    "                gen_train,\n",
    "                samples_per_epoch=nb_train,\n",
    "                nb_epoch=30,\n",
    "                # In parallel to training, a CPU process loads and preprocesses data from disk and put\n",
    "                # it into a queue in the form of mini-batches of size `batch_size`.`max_q_size` controls \n",
    "                # the maximum size of that queue.\n",
    "                # The size of the queue should be big enough so that the training process (GPU) never\n",
    "                # waits for data (the queue should be never be empty). \n",
    "                # The CPU process loads chunks of 1024 images each time, and\n",
    "                # 1024/batch_size mini-batches from that chunk are put into the queue.\n",
    "                # Assuming training the model on those 1024/batch_size mini-batches is slower than \n",
    "                # loading a single chunk of 1024 images, a good lower bound for `max_q_size` would be\n",
    "                # (1024/batch_size). if `batch_size` is 16, you can put `max_q_size` to 64.\n",
    "                max_q_size=16,\n",
    "                # WARNING : It is obligatory to set `nb_worker` to 1.\n",
    "                # This in principle controls the number of workers used\n",
    "                # by keras to load mini-batches from disk to memory in parallel\n",
    "                # to GPU training. But I don't like the way it works and their\n",
    "                # code is not very commented/used, so I dont trust it that much\n",
    "                # (we might have surprises).\n",
    "                # The way it works in keras is by launching in parallel `nb_worker` \n",
    "                # threads or processes which will all use a copy of the generator passed.\n",
    "                # to `fit_generator`. So if nothing is done and `nb_worker` is set to \n",
    "                # some number > 1, the neural net will be trained with repetitions \n",
    "                # of the same data, because the workers are independent and they got \n",
    "                # through the same generator. \n",
    "                # Hence it is necessary to introduce a shared lock between the the \n",
    "                # processes so that they load different data, this can become a bit \n",
    "                # complicated, so I choose to rather load exactly one chunk at a time using \n",
    "                # 1 worker (so `nb_worker` have to be equal to 1), but do this single\n",
    "                # chunk loading in parallel with joblib.\n",
    "                nb_worker=1,\n",
    "                # if pickle_safe is True, processes are used instead of threads.\n",
    "                # here, 1 process is used because `nb_worker` is 1.\n",
    "                pickle_safe=True,\n",
    "                validation_data=gen_valid,\n",
    "                nb_val_samples=nb_valid,\n",
    "                verbose=1)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.model.predict(X)\n",
    "        \n",
    "def build_model():\n",
    "    vgg16 = VGG16(include_top=False, weights='imagenet')\n",
    "    vgg16.trainable = False\n",
    "    inp = vgg16.get_layer(name='input_1')\n",
    "    hid = vgg16.get_layer(name='block3_conv3')\n",
    "    vgg16_hid = Model(inp.input, hid.output)\n",
    "\n",
    "    inp = Input((3, 224, 224))\n",
    "    x = vgg16_hid(inp)\n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(500, activation='relu', name='fc')(x)\n",
    "    out = Dense(209, activation='softmax', name='predictions')(x)\n",
    "    model = Model(inp, out)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=1e-4, momentum=0.95), metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget to run\n",
    "\n",
    "python user_test_submission.py\n",
    "\n",
    "before submitting."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
