<i> Balázs Kégl (CNRS), Camille Marini (CNRS), Andy Rhines (UW), Jennifer Dy (NEU), Arindam Banerjee (UMN) </i><br>
    
<h2>Introduction</h2>

Arctic sea ice cover is one of the most variable features of Earth's climate. Its annual cycle peaks at around 15 million square kilometers in early spring, melting back to a minimum of about 6 million square kilometers in September. These seasonal swings are important for Earth's energy balance, as ice reflects the majority of sunlight while open water absorbs it. Changes in ice cover are also important for marine life and navigation for shipping.
<p>

<center><img src=https://s3-us-west-2.amazonaws.com/artemp/arctic_min_max_map.png width=75%></center></p>

<p>
In recent years, Arctic sea ice cover has declined rapidly, particularly during the September minimum. These changes have outpaced the predictions of climate models, and forecasting extent remains a formidable challenge. Typically, skillful predictions are limited to ~2-5 months in advance (<a href=https://eos.org/features/improving-predictions-of-arctic-sea-ice-extent>Stroeve, et al. "Improving Predictions of Arctic Sea Ice Extent"</a>), while idealized experiments suggest that predictions up to two years in advance should be possible (<a href=http://onlinelibrary.wiley.com/doi/10.1002/qj.2401/abstract>Guemas et al, 2014</a>).
</p>

<p>
<center><img src=https://s3-us-west-2.amazonaws.com/artemp/sea-ice.jpg width=75%></center></p>
<p>
Better tools to predict ice cover are critical for seasonal and regional climate prediction, and would thus address grand challenges in the study of climate change (<a href=http://wcrp-climate.org/grand-challenges>World Climate Research Programme: Grand Challenges, 2013)</a>
</p>

<h3>The CCSM4 simulator</h3>

As a surrogate for observational data, we will use output from a 1300 year simulation using the NCAR <a href=http://www.cesm.ucar.edu/models/ccsm4.0/>CCSM4.0</a> climate model. The model was run in fully-coupled mode with interactive ocean, atmosphere, and sea ice. The simulation was also performed in an idealized "Pre-Industrial" mode, where greenhouse gas concentrations and other external forcings are held fixed to 1850 levels. This allows us to access a  stationary climate over a 1000+ year period, which makes the evaluation of the predictor more robust than if we used real measurements that are both non-stationary and limited to several decades.

<h3>The data</h3>

The data is a time series of "images" $z_t$, consisting of different physical variables on a regular grid on the Earth, indexed by lon(gitude) and lat(itude) coordinates. The variables we have made available are: 
<ul>
<li>ice_area --- the Northern Hemisphere sea ice area, in millions of squared kilometers.
<li>ts --- surface temperature, most important over the oceans which have a very high heat capacity.
<li>taux --- zonal (x-direction) surface wind stress. This is the frictional effect of winds on the sea surface and sea ice.
<li>tauy --- meridional (y-direction) surface wind stress.
<li>ps --- surface pressure.
<li>psl --- equivalent sea-level surface pressure. This corrects ps for the effects of topography, though the two should be very similar.
<li>shflx --- Surface sensible heat flux, the amount of heat transferred from the surface to the atmosphere.
<li>cldtot --- Total cloud cover (fractional), which has strong effects on radiative energy balance at the surface.
</ul>
The fields are recorded every month for 1300 years, giving 15,600 time points. The goal is to predict the Northern Hemisphere sea ice area <span style="color:red">4 months ahead</span>. Since the most important prediction is the minimum area in September, we will also display the RMSE over predictions in May, predecting that years (minimum) ice area in September.

<h3>The prediction task</h3>

The pipeline will consists of a time series feature extractor and a predictor. Since the task is regression, the predictor will be a regressor, and the score (to minimize) will be the <a href=http://en.wikipedia.org/wiki/Root-mean-square_deviation>root mean square error</a>. The feature extractor will have access to the whole data. It will construct a "classical" feature matrix where each row corresponds to a time point. You should collect all information into these features that you find relevant to the regressor. The feature extractor can take <span style="color:red">anything from the past</span>, that is, it will implement a function $x_t = f(z_1, \ldots, z_t)$. Since you will have access to the full data, in theory you can cheat (even inadvertantly) by using information from the future. We have implemented a randomized test to find such "bugs", but please do your best to avoid this since it would make the results irrelevant.
